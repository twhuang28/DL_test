{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('crv_data/train.csv')\n",
    "test = pd.read_csv('crv_data/test_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>TXKEY</th>\n",
       "      <th>V1</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>...</th>\n",
       "      <th>V28</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>normTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>T43428</td>\n",
       "      <td>-16.526507</td>\n",
       "      <td>-14.110184</td>\n",
       "      <td>5.299236</td>\n",
       "      <td>-10.834006</td>\n",
       "      <td>1.671120</td>\n",
       "      <td>-9.373859</td>\n",
       "      <td>0.360806</td>\n",
       "      <td>-9.899247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.042804</td>\n",
       "      <td>-18.649853</td>\n",
       "      <td>9.505594</td>\n",
       "      <td>-13.793819</td>\n",
       "      <td>-2.832404</td>\n",
       "      <td>-16.701694</td>\n",
       "      <td>7.517344</td>\n",
       "      <td>-8.507059</td>\n",
       "      <td>1.102834</td>\n",
       "      <td>-1.122574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T49906</td>\n",
       "      <td>0.339812</td>\n",
       "      <td>-0.565012</td>\n",
       "      <td>-0.087670</td>\n",
       "      <td>0.979427</td>\n",
       "      <td>0.076883</td>\n",
       "      <td>-0.217884</td>\n",
       "      <td>-0.136830</td>\n",
       "      <td>-2.142892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102038</td>\n",
       "      <td>-0.134070</td>\n",
       "      <td>-1.385729</td>\n",
       "      <td>-1.451413</td>\n",
       "      <td>1.015887</td>\n",
       "      <td>-0.524379</td>\n",
       "      <td>0.224060</td>\n",
       "      <td>0.899746</td>\n",
       "      <td>1.726255</td>\n",
       "      <td>-1.064538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T29474</td>\n",
       "      <td>1.399590</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.543827</td>\n",
       "      <td>0.112453</td>\n",
       "      <td>1.075384</td>\n",
       "      <td>-0.245772</td>\n",
       "      <td>0.180483</td>\n",
       "      <td>1.769860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.168619</td>\n",
       "      <td>-1.029950</td>\n",
       "      <td>-0.539806</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>-0.712567</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>-0.971747</td>\n",
       "      <td>-0.229289</td>\n",
       "      <td>-1.249364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T276481</td>\n",
       "      <td>-0.432071</td>\n",
       "      <td>-1.376648</td>\n",
       "      <td>-1.328335</td>\n",
       "      <td>0.223621</td>\n",
       "      <td>1.132627</td>\n",
       "      <td>-0.550875</td>\n",
       "      <td>0.616568</td>\n",
       "      <td>0.497974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>-1.669361</td>\n",
       "      <td>-0.349504</td>\n",
       "      <td>0.785785</td>\n",
       "      <td>-0.630647</td>\n",
       "      <td>0.276990</td>\n",
       "      <td>0.586025</td>\n",
       "      <td>-0.484715</td>\n",
       "      <td>-0.347232</td>\n",
       "      <td>1.522680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T278846</td>\n",
       "      <td>2.014160</td>\n",
       "      <td>0.259452</td>\n",
       "      <td>0.942162</td>\n",
       "      <td>0.850038</td>\n",
       "      <td>-0.616166</td>\n",
       "      <td>0.592634</td>\n",
       "      <td>-0.603845</td>\n",
       "      <td>0.091077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-1.015839</td>\n",
       "      <td>0.327269</td>\n",
       "      <td>-0.182179</td>\n",
       "      <td>-0.956571</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>-0.160746</td>\n",
       "      <td>0.363241</td>\n",
       "      <td>-0.349671</td>\n",
       "      <td>1.551109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T101565</td>\n",
       "      <td>-0.641330</td>\n",
       "      <td>-2.084080</td>\n",
       "      <td>0.480381</td>\n",
       "      <td>0.473738</td>\n",
       "      <td>-2.192276</td>\n",
       "      <td>0.773942</td>\n",
       "      <td>0.294484</td>\n",
       "      <td>0.406074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180357</td>\n",
       "      <td>1.489998</td>\n",
       "      <td>-1.688131</td>\n",
       "      <td>-1.151043</td>\n",
       "      <td>0.259996</td>\n",
       "      <td>-1.391069</td>\n",
       "      <td>-2.334075</td>\n",
       "      <td>1.168644</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>-0.567213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T260880</td>\n",
       "      <td>2.023952</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>-0.720047</td>\n",
       "      <td>0.366835</td>\n",
       "      <td>-0.110857</td>\n",
       "      <td>0.319094</td>\n",
       "      <td>0.108359</td>\n",
       "      <td>-0.153633</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058224</td>\n",
       "      <td>-1.086918</td>\n",
       "      <td>0.423019</td>\n",
       "      <td>-0.142901</td>\n",
       "      <td>-1.127752</td>\n",
       "      <td>0.178493</td>\n",
       "      <td>-0.303234</td>\n",
       "      <td>0.564509</td>\n",
       "      <td>-0.285302</td>\n",
       "      <td>1.367694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T214337</td>\n",
       "      <td>-0.688944</td>\n",
       "      <td>-1.303435</td>\n",
       "      <td>0.282728</td>\n",
       "      <td>-0.402525</td>\n",
       "      <td>-0.548687</td>\n",
       "      <td>-0.504283</td>\n",
       "      <td>-0.685339</td>\n",
       "      <td>0.714828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>-0.564281</td>\n",
       "      <td>-1.457526</td>\n",
       "      <td>2.258333</td>\n",
       "      <td>-0.323270</td>\n",
       "      <td>1.678984</td>\n",
       "      <td>-0.104128</td>\n",
       "      <td>-1.285351</td>\n",
       "      <td>-0.317447</td>\n",
       "      <td>0.943756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T201575</td>\n",
       "      <td>2.119362</td>\n",
       "      <td>0.295305</td>\n",
       "      <td>-0.936569</td>\n",
       "      <td>-0.452478</td>\n",
       "      <td>-1.340798</td>\n",
       "      <td>1.077459</td>\n",
       "      <td>-0.099584</td>\n",
       "      <td>-0.815072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094713</td>\n",
       "      <td>-2.373337</td>\n",
       "      <td>0.541949</td>\n",
       "      <td>0.608419</td>\n",
       "      <td>-1.775564</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>-0.599383</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>0.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T81055</td>\n",
       "      <td>-5.584256</td>\n",
       "      <td>-0.942358</td>\n",
       "      <td>-2.439501</td>\n",
       "      <td>-0.552312</td>\n",
       "      <td>-0.295588</td>\n",
       "      <td>-0.250246</td>\n",
       "      <td>-1.197732</td>\n",
       "      <td>1.549553</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.898323</td>\n",
       "      <td>-0.448452</td>\n",
       "      <td>-0.121442</td>\n",
       "      <td>-0.707412</td>\n",
       "      <td>-0.114376</td>\n",
       "      <td>-1.554628</td>\n",
       "      <td>1.402126</td>\n",
       "      <td>-0.031693</td>\n",
       "      <td>0.052536</td>\n",
       "      <td>-0.759030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T134976</td>\n",
       "      <td>-1.593002</td>\n",
       "      <td>-0.819436</td>\n",
       "      <td>0.362193</td>\n",
       "      <td>0.436745</td>\n",
       "      <td>-1.148969</td>\n",
       "      <td>0.573126</td>\n",
       "      <td>-1.215218</td>\n",
       "      <td>-0.130036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039483</td>\n",
       "      <td>1.274002</td>\n",
       "      <td>0.244127</td>\n",
       "      <td>0.335045</td>\n",
       "      <td>0.272886</td>\n",
       "      <td>0.389542</td>\n",
       "      <td>0.676944</td>\n",
       "      <td>-0.579539</td>\n",
       "      <td>-0.179313</td>\n",
       "      <td>-0.289733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T237701</td>\n",
       "      <td>1.911979</td>\n",
       "      <td>-0.666750</td>\n",
       "      <td>0.255346</td>\n",
       "      <td>0.286835</td>\n",
       "      <td>-0.021013</td>\n",
       "      <td>-1.277795</td>\n",
       "      <td>1.402421</td>\n",
       "      <td>0.712419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003322</td>\n",
       "      <td>-1.878744</td>\n",
       "      <td>-0.478891</td>\n",
       "      <td>1.775020</td>\n",
       "      <td>3.807866</td>\n",
       "      <td>-1.349298</td>\n",
       "      <td>1.116637</td>\n",
       "      <td>1.329865</td>\n",
       "      <td>-0.266831</td>\n",
       "      <td>1.148565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T256836</td>\n",
       "      <td>1.856004</td>\n",
       "      <td>0.953865</td>\n",
       "      <td>-2.006995</td>\n",
       "      <td>-0.609613</td>\n",
       "      <td>-0.204192</td>\n",
       "      <td>0.036315</td>\n",
       "      <td>0.317903</td>\n",
       "      <td>-1.063353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-1.094526</td>\n",
       "      <td>0.536984</td>\n",
       "      <td>-0.460547</td>\n",
       "      <td>0.257930</td>\n",
       "      <td>-0.548791</td>\n",
       "      <td>-0.006732</td>\n",
       "      <td>-0.136465</td>\n",
       "      <td>0.270472</td>\n",
       "      <td>1.328147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T97650</td>\n",
       "      <td>-0.745324</td>\n",
       "      <td>-0.366034</td>\n",
       "      <td>0.029744</td>\n",
       "      <td>0.405037</td>\n",
       "      <td>-0.127257</td>\n",
       "      <td>1.134589</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.237010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118392</td>\n",
       "      <td>-0.240708</td>\n",
       "      <td>0.592741</td>\n",
       "      <td>0.036572</td>\n",
       "      <td>0.642731</td>\n",
       "      <td>-0.098414</td>\n",
       "      <td>1.009457</td>\n",
       "      <td>-0.931697</td>\n",
       "      <td>-0.185310</td>\n",
       "      <td>-0.600127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T158290</td>\n",
       "      <td>-0.198807</td>\n",
       "      <td>-0.625276</td>\n",
       "      <td>-0.448324</td>\n",
       "      <td>-3.341578</td>\n",
       "      <td>0.365717</td>\n",
       "      <td>2.134383</td>\n",
       "      <td>0.308015</td>\n",
       "      <td>-0.519039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289282</td>\n",
       "      <td>-0.113648</td>\n",
       "      <td>-0.246482</td>\n",
       "      <td>0.751390</td>\n",
       "      <td>-0.359111</td>\n",
       "      <td>0.493849</td>\n",
       "      <td>-0.948922</td>\n",
       "      <td>1.573062</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0.343289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T246697</td>\n",
       "      <td>-3.608205</td>\n",
       "      <td>0.769870</td>\n",
       "      <td>0.132041</td>\n",
       "      <td>0.610286</td>\n",
       "      <td>1.033143</td>\n",
       "      <td>-1.937054</td>\n",
       "      <td>0.323444</td>\n",
       "      <td>0.261689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059786</td>\n",
       "      <td>0.327140</td>\n",
       "      <td>0.149964</td>\n",
       "      <td>3.666915</td>\n",
       "      <td>-2.701360</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>-0.522986</td>\n",
       "      <td>1.115929</td>\n",
       "      <td>-0.319086</td>\n",
       "      <td>1.231386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T68279</td>\n",
       "      <td>0.676855</td>\n",
       "      <td>-0.323058</td>\n",
       "      <td>2.967921</td>\n",
       "      <td>-0.155026</td>\n",
       "      <td>-0.717766</td>\n",
       "      <td>-3.709275</td>\n",
       "      <td>0.731050</td>\n",
       "      <td>0.510125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383642</td>\n",
       "      <td>-1.508147</td>\n",
       "      <td>1.443815</td>\n",
       "      <td>1.316790</td>\n",
       "      <td>-1.160342</td>\n",
       "      <td>1.149049</td>\n",
       "      <td>-0.419393</td>\n",
       "      <td>-0.090565</td>\n",
       "      <td>-0.349671</td>\n",
       "      <td>-0.882345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T267585</td>\n",
       "      <td>-2.537172</td>\n",
       "      <td>1.045582</td>\n",
       "      <td>-1.818924</td>\n",
       "      <td>-0.442261</td>\n",
       "      <td>0.609999</td>\n",
       "      <td>0.493009</td>\n",
       "      <td>1.247058</td>\n",
       "      <td>0.872001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081702</td>\n",
       "      <td>1.204914</td>\n",
       "      <td>4.456819</td>\n",
       "      <td>-0.829264</td>\n",
       "      <td>1.473885</td>\n",
       "      <td>-1.182380</td>\n",
       "      <td>1.467687</td>\n",
       "      <td>-1.750166</td>\n",
       "      <td>-0.247400</td>\n",
       "      <td>1.432426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T26525</td>\n",
       "      <td>1.453447</td>\n",
       "      <td>1.404100</td>\n",
       "      <td>-0.758519</td>\n",
       "      <td>-0.795068</td>\n",
       "      <td>0.834501</td>\n",
       "      <td>-0.169291</td>\n",
       "      <td>0.368825</td>\n",
       "      <td>-0.433712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>-0.134962</td>\n",
       "      <td>-1.418547</td>\n",
       "      <td>-1.057755</td>\n",
       "      <td>-0.948851</td>\n",
       "      <td>-0.461141</td>\n",
       "      <td>-0.350840</td>\n",
       "      <td>-2.149149</td>\n",
       "      <td>-0.049375</td>\n",
       "      <td>-1.278129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T74422</td>\n",
       "      <td>-3.419423</td>\n",
       "      <td>1.921982</td>\n",
       "      <td>1.954445</td>\n",
       "      <td>0.388840</td>\n",
       "      <td>0.301474</td>\n",
       "      <td>-0.427868</td>\n",
       "      <td>-0.029227</td>\n",
       "      <td>-0.075064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085630</td>\n",
       "      <td>1.607086</td>\n",
       "      <td>2.229979</td>\n",
       "      <td>2.644089</td>\n",
       "      <td>-0.793538</td>\n",
       "      <td>1.088242</td>\n",
       "      <td>-1.008410</td>\n",
       "      <td>-0.933315</td>\n",
       "      <td>-0.262473</td>\n",
       "      <td>-0.826289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T206357</td>\n",
       "      <td>-0.648081</td>\n",
       "      <td>-1.247178</td>\n",
       "      <td>-0.799046</td>\n",
       "      <td>0.665321</td>\n",
       "      <td>0.386255</td>\n",
       "      <td>0.251692</td>\n",
       "      <td>0.115987</td>\n",
       "      <td>-0.028040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071526</td>\n",
       "      <td>0.112924</td>\n",
       "      <td>-1.535076</td>\n",
       "      <td>-0.191904</td>\n",
       "      <td>-1.208250</td>\n",
       "      <td>0.453343</td>\n",
       "      <td>0.180405</td>\n",
       "      <td>0.389545</td>\n",
       "      <td>-0.169917</td>\n",
       "      <td>0.871022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T257395</td>\n",
       "      <td>-0.859208</td>\n",
       "      <td>0.733837</td>\n",
       "      <td>-1.303173</td>\n",
       "      <td>0.103792</td>\n",
       "      <td>0.612907</td>\n",
       "      <td>0.245690</td>\n",
       "      <td>-0.156256</td>\n",
       "      <td>-0.587316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510106</td>\n",
       "      <td>-1.392449</td>\n",
       "      <td>-1.416790</td>\n",
       "      <td>1.290569</td>\n",
       "      <td>-1.433808</td>\n",
       "      <td>1.730253</td>\n",
       "      <td>-0.468233</td>\n",
       "      <td>0.287973</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>1.333580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T283656</td>\n",
       "      <td>-3.151020</td>\n",
       "      <td>1.096035</td>\n",
       "      <td>-1.406244</td>\n",
       "      <td>0.471208</td>\n",
       "      <td>-0.226161</td>\n",
       "      <td>1.460352</td>\n",
       "      <td>-0.191831</td>\n",
       "      <td>-0.319540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506837</td>\n",
       "      <td>-3.027658</td>\n",
       "      <td>-1.319770</td>\n",
       "      <td>-0.570469</td>\n",
       "      <td>-2.085578</td>\n",
       "      <td>0.223991</td>\n",
       "      <td>1.296731</td>\n",
       "      <td>0.480108</td>\n",
       "      <td>-0.323963</td>\n",
       "      <td>1.620452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T231156</td>\n",
       "      <td>2.019865</td>\n",
       "      <td>0.383761</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>-0.296638</td>\n",
       "      <td>1.017375</td>\n",
       "      <td>0.605096</td>\n",
       "      <td>-0.481818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066625</td>\n",
       "      <td>-3.296257</td>\n",
       "      <td>0.123738</td>\n",
       "      <td>3.078086</td>\n",
       "      <td>3.037019</td>\n",
       "      <td>0.197002</td>\n",
       "      <td>0.576984</td>\n",
       "      <td>-0.306510</td>\n",
       "      <td>-0.257275</td>\n",
       "      <td>1.091246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T38442</td>\n",
       "      <td>-2.151941</td>\n",
       "      <td>-2.681203</td>\n",
       "      <td>-0.595416</td>\n",
       "      <td>0.892896</td>\n",
       "      <td>-0.722106</td>\n",
       "      <td>-0.478067</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>-1.578135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152309</td>\n",
       "      <td>1.904957</td>\n",
       "      <td>-2.287254</td>\n",
       "      <td>-0.330618</td>\n",
       "      <td>-0.971106</td>\n",
       "      <td>-0.067533</td>\n",
       "      <td>0.251995</td>\n",
       "      <td>2.391839</td>\n",
       "      <td>0.773991</td>\n",
       "      <td>-1.167027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T225485</td>\n",
       "      <td>1.786896</td>\n",
       "      <td>-0.241772</td>\n",
       "      <td>-2.203908</td>\n",
       "      <td>0.763546</td>\n",
       "      <td>1.219256</td>\n",
       "      <td>-1.182939</td>\n",
       "      <td>-0.510078</td>\n",
       "      <td>0.511919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022000</td>\n",
       "      <td>0.169414</td>\n",
       "      <td>0.716106</td>\n",
       "      <td>-0.991835</td>\n",
       "      <td>0.798244</td>\n",
       "      <td>-1.181350</td>\n",
       "      <td>0.232048</td>\n",
       "      <td>2.037239</td>\n",
       "      <td>0.082562</td>\n",
       "      <td>1.041380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T92410</td>\n",
       "      <td>0.908419</td>\n",
       "      <td>0.031077</td>\n",
       "      <td>1.249465</td>\n",
       "      <td>0.735582</td>\n",
       "      <td>-0.857612</td>\n",
       "      <td>0.158029</td>\n",
       "      <td>0.219705</td>\n",
       "      <td>0.178133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036881</td>\n",
       "      <td>1.213928</td>\n",
       "      <td>1.350973</td>\n",
       "      <td>-0.952296</td>\n",
       "      <td>0.428768</td>\n",
       "      <td>-0.683379</td>\n",
       "      <td>0.366450</td>\n",
       "      <td>0.554730</td>\n",
       "      <td>-0.005396</td>\n",
       "      <td>-0.650561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T10828</td>\n",
       "      <td>-1.544409</td>\n",
       "      <td>-0.722311</td>\n",
       "      <td>0.789475</td>\n",
       "      <td>-3.035002</td>\n",
       "      <td>0.568386</td>\n",
       "      <td>1.287709</td>\n",
       "      <td>-0.461989</td>\n",
       "      <td>1.132222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191005</td>\n",
       "      <td>0.671990</td>\n",
       "      <td>-0.625734</td>\n",
       "      <td>1.953606</td>\n",
       "      <td>0.231276</td>\n",
       "      <td>-0.017919</td>\n",
       "      <td>0.125894</td>\n",
       "      <td>1.198210</td>\n",
       "      <td>-0.265311</td>\n",
       "      <td>-1.607243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T61461</td>\n",
       "      <td>1.104574</td>\n",
       "      <td>-0.242497</td>\n",
       "      <td>1.112838</td>\n",
       "      <td>0.731945</td>\n",
       "      <td>-0.971919</td>\n",
       "      <td>-0.034381</td>\n",
       "      <td>-0.048560</td>\n",
       "      <td>0.111454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>1.127897</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>-1.083712</td>\n",
       "      <td>0.308094</td>\n",
       "      <td>-0.917052</td>\n",
       "      <td>0.377067</td>\n",
       "      <td>0.969331</td>\n",
       "      <td>-0.265471</td>\n",
       "      <td>-0.946888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>T134354</td>\n",
       "      <td>-0.593356</td>\n",
       "      <td>-0.540724</td>\n",
       "      <td>-1.220295</td>\n",
       "      <td>0.292569</td>\n",
       "      <td>-0.376230</td>\n",
       "      <td>-0.608940</td>\n",
       "      <td>-1.441187</td>\n",
       "      <td>-1.001776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162494</td>\n",
       "      <td>0.656265</td>\n",
       "      <td>0.642976</td>\n",
       "      <td>1.974441</td>\n",
       "      <td>4.632349</td>\n",
       "      <td>-0.366834</td>\n",
       "      <td>1.219162</td>\n",
       "      <td>0.412184</td>\n",
       "      <td>0.022391</td>\n",
       "      <td>-0.295777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284777</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284703</td>\n",
       "      <td>1.019594</td>\n",
       "      <td>-0.403165</td>\n",
       "      <td>-0.090503</td>\n",
       "      <td>1.230074</td>\n",
       "      <td>0.367173</td>\n",
       "      <td>0.173777</td>\n",
       "      <td>-0.563206</td>\n",
       "      <td>0.246397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>-1.431268</td>\n",
       "      <td>0.539727</td>\n",
       "      <td>-0.499995</td>\n",
       "      <td>0.301251</td>\n",
       "      <td>0.326079</td>\n",
       "      <td>-0.062475</td>\n",
       "      <td>1.121288</td>\n",
       "      <td>1.733372</td>\n",
       "      <td>1.640099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284778</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284704</td>\n",
       "      <td>-1.269721</td>\n",
       "      <td>-1.409373</td>\n",
       "      <td>-1.749021</td>\n",
       "      <td>-0.335999</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>-1.098655</td>\n",
       "      <td>0.473234</td>\n",
       "      <td>1.015379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135902</td>\n",
       "      <td>0.131330</td>\n",
       "      <td>-1.065236</td>\n",
       "      <td>0.107397</td>\n",
       "      <td>-0.307148</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.678313</td>\n",
       "      <td>0.459493</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>1.640120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284706</td>\n",
       "      <td>1.690720</td>\n",
       "      <td>1.296770</td>\n",
       "      <td>-2.004073</td>\n",
       "      <td>-0.196385</td>\n",
       "      <td>0.808469</td>\n",
       "      <td>-0.418867</td>\n",
       "      <td>-0.530816</td>\n",
       "      <td>1.419129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009875</td>\n",
       "      <td>-0.299329</td>\n",
       "      <td>3.698813</td>\n",
       "      <td>0.190589</td>\n",
       "      <td>1.137963</td>\n",
       "      <td>-0.405899</td>\n",
       "      <td>0.186784</td>\n",
       "      <td>-0.307412</td>\n",
       "      <td>0.162204</td>\n",
       "      <td>1.640120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284780</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284721</td>\n",
       "      <td>-2.516013</td>\n",
       "      <td>2.213231</td>\n",
       "      <td>0.492104</td>\n",
       "      <td>0.351730</td>\n",
       "      <td>1.156920</td>\n",
       "      <td>-2.276737</td>\n",
       "      <td>0.803360</td>\n",
       "      <td>-0.700136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222766</td>\n",
       "      <td>-0.683786</td>\n",
       "      <td>-0.621718</td>\n",
       "      <td>0.596987</td>\n",
       "      <td>-1.384147</td>\n",
       "      <td>1.579089</td>\n",
       "      <td>-1.314013</td>\n",
       "      <td>1.618929</td>\n",
       "      <td>-0.323444</td>\n",
       "      <td>1.640331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284725</td>\n",
       "      <td>-0.364673</td>\n",
       "      <td>-0.641531</td>\n",
       "      <td>-1.265308</td>\n",
       "      <td>-1.264948</td>\n",
       "      <td>-0.846889</td>\n",
       "      <td>-0.272673</td>\n",
       "      <td>2.381906</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089564</td>\n",
       "      <td>-0.728575</td>\n",
       "      <td>0.942156</td>\n",
       "      <td>0.690695</td>\n",
       "      <td>-0.142101</td>\n",
       "      <td>0.279193</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>-0.563470</td>\n",
       "      <td>-0.311010</td>\n",
       "      <td>1.640373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284782</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284726</td>\n",
       "      <td>1.615707</td>\n",
       "      <td>0.394148</td>\n",
       "      <td>0.319164</td>\n",
       "      <td>-0.657936</td>\n",
       "      <td>-2.910623</td>\n",
       "      <td>0.819779</td>\n",
       "      <td>0.511679</td>\n",
       "      <td>0.777601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012795</td>\n",
       "      <td>-0.562272</td>\n",
       "      <td>1.260583</td>\n",
       "      <td>-0.684711</td>\n",
       "      <td>0.234819</td>\n",
       "      <td>-0.643286</td>\n",
       "      <td>0.329931</td>\n",
       "      <td>1.064298</td>\n",
       "      <td>0.286464</td>\n",
       "      <td>1.640436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284783</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284727</td>\n",
       "      <td>-3.240505</td>\n",
       "      <td>-0.765409</td>\n",
       "      <td>-0.341543</td>\n",
       "      <td>0.656896</td>\n",
       "      <td>0.744721</td>\n",
       "      <td>0.067701</td>\n",
       "      <td>0.621832</td>\n",
       "      <td>1.051746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501609</td>\n",
       "      <td>1.749777</td>\n",
       "      <td>0.332355</td>\n",
       "      <td>1.535180</td>\n",
       "      <td>-0.574599</td>\n",
       "      <td>-2.131128</td>\n",
       "      <td>1.034499</td>\n",
       "      <td>0.110722</td>\n",
       "      <td>-0.145329</td>\n",
       "      <td>1.640457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284784</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284732</td>\n",
       "      <td>1.076175</td>\n",
       "      <td>1.269149</td>\n",
       "      <td>-0.702987</td>\n",
       "      <td>-0.030576</td>\n",
       "      <td>1.739927</td>\n",
       "      <td>-0.262265</td>\n",
       "      <td>-0.561099</td>\n",
       "      <td>-0.902514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056029</td>\n",
       "      <td>-2.051439</td>\n",
       "      <td>-0.953189</td>\n",
       "      <td>-1.544838</td>\n",
       "      <td>-1.124645</td>\n",
       "      <td>0.385570</td>\n",
       "      <td>-0.698014</td>\n",
       "      <td>-1.829401</td>\n",
       "      <td>2.303899</td>\n",
       "      <td>1.640563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284785</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284735</td>\n",
       "      <td>-1.661169</td>\n",
       "      <td>-0.514510</td>\n",
       "      <td>-1.035375</td>\n",
       "      <td>-0.968981</td>\n",
       "      <td>-1.664493</td>\n",
       "      <td>-0.370165</td>\n",
       "      <td>-0.280621</td>\n",
       "      <td>0.371750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.448621</td>\n",
       "      <td>0.294268</td>\n",
       "      <td>-1.549156</td>\n",
       "      <td>-2.301359</td>\n",
       "      <td>2.365956</td>\n",
       "      <td>-0.248881</td>\n",
       "      <td>-0.857361</td>\n",
       "      <td>0.137784</td>\n",
       "      <td>1.170241</td>\n",
       "      <td>1.640689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284786</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284738</td>\n",
       "      <td>-1.117799</td>\n",
       "      <td>2.911750</td>\n",
       "      <td>-0.888295</td>\n",
       "      <td>-0.319556</td>\n",
       "      <td>1.227808</td>\n",
       "      <td>-0.829885</td>\n",
       "      <td>0.875202</td>\n",
       "      <td>-0.094147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273686</td>\n",
       "      <td>1.822761</td>\n",
       "      <td>4.243919</td>\n",
       "      <td>0.043986</td>\n",
       "      <td>0.761828</td>\n",
       "      <td>0.297293</td>\n",
       "      <td>-0.111319</td>\n",
       "      <td>-0.769844</td>\n",
       "      <td>-0.301854</td>\n",
       "      <td>1.640773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284787</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284740</td>\n",
       "      <td>-0.846934</td>\n",
       "      <td>-0.321648</td>\n",
       "      <td>-0.555733</td>\n",
       "      <td>-0.565739</td>\n",
       "      <td>-0.232108</td>\n",
       "      <td>-0.591077</td>\n",
       "      <td>-0.183204</td>\n",
       "      <td>1.705102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166451</td>\n",
       "      <td>2.160620</td>\n",
       "      <td>-1.935812</td>\n",
       "      <td>-1.864416</td>\n",
       "      <td>-0.939825</td>\n",
       "      <td>-0.972629</td>\n",
       "      <td>0.600049</td>\n",
       "      <td>-0.266026</td>\n",
       "      <td>-0.305292</td>\n",
       "      <td>1.640815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284742</td>\n",
       "      <td>-1.248847</td>\n",
       "      <td>-2.518802</td>\n",
       "      <td>-0.743766</td>\n",
       "      <td>1.157013</td>\n",
       "      <td>0.442445</td>\n",
       "      <td>-0.078341</td>\n",
       "      <td>-0.461857</td>\n",
       "      <td>0.477430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082714</td>\n",
       "      <td>-1.144824</td>\n",
       "      <td>-0.263061</td>\n",
       "      <td>0.070912</td>\n",
       "      <td>-0.323414</td>\n",
       "      <td>-1.454139</td>\n",
       "      <td>-5.069379</td>\n",
       "      <td>-0.827733</td>\n",
       "      <td>-0.313289</td>\n",
       "      <td>1.640836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284748</td>\n",
       "      <td>1.634178</td>\n",
       "      <td>-0.990124</td>\n",
       "      <td>-0.321001</td>\n",
       "      <td>1.131826</td>\n",
       "      <td>1.612595</td>\n",
       "      <td>-1.754129</td>\n",
       "      <td>-0.236948</td>\n",
       "      <td>-0.011848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024884</td>\n",
       "      <td>-1.975967</td>\n",
       "      <td>0.495364</td>\n",
       "      <td>0.263635</td>\n",
       "      <td>-0.713049</td>\n",
       "      <td>0.459925</td>\n",
       "      <td>-0.336879</td>\n",
       "      <td>0.743676</td>\n",
       "      <td>0.527469</td>\n",
       "      <td>1.640921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284790</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284753</td>\n",
       "      <td>1.465737</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>-0.926921</td>\n",
       "      <td>0.218557</td>\n",
       "      <td>0.101360</td>\n",
       "      <td>0.916400</td>\n",
       "      <td>-0.231472</td>\n",
       "      <td>-0.825682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014737</td>\n",
       "      <td>-2.851391</td>\n",
       "      <td>1.425282</td>\n",
       "      <td>0.893893</td>\n",
       "      <td>-0.958325</td>\n",
       "      <td>1.508074</td>\n",
       "      <td>-0.625691</td>\n",
       "      <td>-0.369824</td>\n",
       "      <td>0.996285</td>\n",
       "      <td>1.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284791</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284755</td>\n",
       "      <td>-0.954967</td>\n",
       "      <td>-1.269369</td>\n",
       "      <td>-0.960160</td>\n",
       "      <td>0.459340</td>\n",
       "      <td>0.586295</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>0.578975</td>\n",
       "      <td>0.046778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014827</td>\n",
       "      <td>1.780434</td>\n",
       "      <td>-0.361532</td>\n",
       "      <td>-0.407570</td>\n",
       "      <td>-0.406413</td>\n",
       "      <td>0.210387</td>\n",
       "      <td>0.429851</td>\n",
       "      <td>-0.173493</td>\n",
       "      <td>-0.313289</td>\n",
       "      <td>1.641047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284792</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284760</td>\n",
       "      <td>-0.657393</td>\n",
       "      <td>0.541037</td>\n",
       "      <td>-0.131550</td>\n",
       "      <td>0.061860</td>\n",
       "      <td>-0.374501</td>\n",
       "      <td>0.143281</td>\n",
       "      <td>0.087590</td>\n",
       "      <td>-0.217749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281084</td>\n",
       "      <td>-1.498162</td>\n",
       "      <td>-1.889374</td>\n",
       "      <td>2.819520</td>\n",
       "      <td>3.333925</td>\n",
       "      <td>0.287569</td>\n",
       "      <td>0.958604</td>\n",
       "      <td>0.408711</td>\n",
       "      <td>-0.346113</td>\n",
       "      <td>1.641152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284793</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284766</td>\n",
       "      <td>-0.564412</td>\n",
       "      <td>-0.452610</td>\n",
       "      <td>-0.838950</td>\n",
       "      <td>0.118004</td>\n",
       "      <td>0.355978</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.256386</td>\n",
       "      <td>-1.846704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155795</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>-1.775612</td>\n",
       "      <td>0.116635</td>\n",
       "      <td>1.116266</td>\n",
       "      <td>-0.211710</td>\n",
       "      <td>0.823119</td>\n",
       "      <td>-1.024449</td>\n",
       "      <td>0.029108</td>\n",
       "      <td>1.641300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284794</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284768</td>\n",
       "      <td>-0.546378</td>\n",
       "      <td>-0.077753</td>\n",
       "      <td>0.534689</td>\n",
       "      <td>0.748099</td>\n",
       "      <td>-0.338301</td>\n",
       "      <td>1.018502</td>\n",
       "      <td>-1.058923</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173585</td>\n",
       "      <td>-0.313252</td>\n",
       "      <td>0.926044</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>-0.565669</td>\n",
       "      <td>1.066075</td>\n",
       "      <td>0.269799</td>\n",
       "      <td>-1.099446</td>\n",
       "      <td>-0.207259</td>\n",
       "      <td>1.641342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284795</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284771</td>\n",
       "      <td>1.894910</td>\n",
       "      <td>-0.155285</td>\n",
       "      <td>-1.490405</td>\n",
       "      <td>-0.316953</td>\n",
       "      <td>-0.827955</td>\n",
       "      <td>0.743761</td>\n",
       "      <td>0.642005</td>\n",
       "      <td>-0.380035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040441</td>\n",
       "      <td>-2.184267</td>\n",
       "      <td>0.159979</td>\n",
       "      <td>0.587740</td>\n",
       "      <td>-0.557966</td>\n",
       "      <td>0.510524</td>\n",
       "      <td>-0.281590</td>\n",
       "      <td>0.785446</td>\n",
       "      <td>0.146491</td>\n",
       "      <td>1.641363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284796</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284772</td>\n",
       "      <td>-6.713826</td>\n",
       "      <td>2.769699</td>\n",
       "      <td>-1.476424</td>\n",
       "      <td>-0.076365</td>\n",
       "      <td>-0.755724</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>1.018209</td>\n",
       "      <td>0.099797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474584</td>\n",
       "      <td>-3.534768</td>\n",
       "      <td>-0.368259</td>\n",
       "      <td>-1.721030</td>\n",
       "      <td>-1.322808</td>\n",
       "      <td>-0.190876</td>\n",
       "      <td>0.891149</td>\n",
       "      <td>2.068476</td>\n",
       "      <td>-0.274907</td>\n",
       "      <td>1.641384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284797</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284775</td>\n",
       "      <td>1.955547</td>\n",
       "      <td>-0.150553</td>\n",
       "      <td>-0.222844</td>\n",
       "      <td>0.496839</td>\n",
       "      <td>-0.050358</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.894690</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042323</td>\n",
       "      <td>-1.706511</td>\n",
       "      <td>-0.611145</td>\n",
       "      <td>1.710907</td>\n",
       "      <td>3.914215</td>\n",
       "      <td>-1.248690</td>\n",
       "      <td>1.054133</td>\n",
       "      <td>1.314064</td>\n",
       "      <td>-0.301294</td>\n",
       "      <td>1.641426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284798</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284778</td>\n",
       "      <td>-0.764523</td>\n",
       "      <td>-1.245088</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.162691</td>\n",
       "      <td>-1.011819</td>\n",
       "      <td>-0.317789</td>\n",
       "      <td>-0.887823</td>\n",
       "      <td>0.482847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065285</td>\n",
       "      <td>-0.907599</td>\n",
       "      <td>-0.418847</td>\n",
       "      <td>0.901528</td>\n",
       "      <td>-0.760802</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.414698</td>\n",
       "      <td>-0.730854</td>\n",
       "      <td>-0.033382</td>\n",
       "      <td>1.641468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284799</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284784</td>\n",
       "      <td>-0.669662</td>\n",
       "      <td>-1.453432</td>\n",
       "      <td>0.187488</td>\n",
       "      <td>-0.390794</td>\n",
       "      <td>-0.289171</td>\n",
       "      <td>-0.510320</td>\n",
       "      <td>0.955637</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187719</td>\n",
       "      <td>-1.543167</td>\n",
       "      <td>-1.560729</td>\n",
       "      <td>2.833960</td>\n",
       "      <td>3.240843</td>\n",
       "      <td>0.181576</td>\n",
       "      <td>1.282746</td>\n",
       "      <td>-0.893890</td>\n",
       "      <td>-0.193306</td>\n",
       "      <td>1.641552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284800</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284785</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>-0.386953</td>\n",
       "      <td>-0.199626</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>-0.374731</td>\n",
       "      <td>0.354051</td>\n",
       "      <td>0.041228</td>\n",
       "      <td>-0.154750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090245</td>\n",
       "      <td>-1.185844</td>\n",
       "      <td>-1.729828</td>\n",
       "      <td>2.932315</td>\n",
       "      <td>3.401529</td>\n",
       "      <td>0.337434</td>\n",
       "      <td>0.925377</td>\n",
       "      <td>-0.165663</td>\n",
       "      <td>-0.346073</td>\n",
       "      <td>1.641552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284788</td>\n",
       "      <td>2.007418</td>\n",
       "      <td>-0.028284</td>\n",
       "      <td>-0.635200</td>\n",
       "      <td>0.869261</td>\n",
       "      <td>0.996596</td>\n",
       "      <td>-0.280317</td>\n",
       "      <td>0.436079</td>\n",
       "      <td>0.397439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>-0.208113</td>\n",
       "      <td>0.335261</td>\n",
       "      <td>-0.715798</td>\n",
       "      <td>-0.751373</td>\n",
       "      <td>-0.458972</td>\n",
       "      <td>-0.140140</td>\n",
       "      <td>0.959971</td>\n",
       "      <td>-0.337277</td>\n",
       "      <td>1.641594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284789</td>\n",
       "      <td>-0.446951</td>\n",
       "      <td>0.076605</td>\n",
       "      <td>-1.291228</td>\n",
       "      <td>-0.690868</td>\n",
       "      <td>-1.481724</td>\n",
       "      <td>0.753473</td>\n",
       "      <td>-0.191141</td>\n",
       "      <td>-1.129904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229921</td>\n",
       "      <td>-0.168583</td>\n",
       "      <td>0.981577</td>\n",
       "      <td>0.578957</td>\n",
       "      <td>-0.605641</td>\n",
       "      <td>1.253430</td>\n",
       "      <td>-1.042610</td>\n",
       "      <td>-0.417116</td>\n",
       "      <td>-0.111345</td>\n",
       "      <td>1.641594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284792</td>\n",
       "      <td>-0.724123</td>\n",
       "      <td>-0.348134</td>\n",
       "      <td>-1.381624</td>\n",
       "      <td>0.617933</td>\n",
       "      <td>1.428297</td>\n",
       "      <td>0.494490</td>\n",
       "      <td>0.426827</td>\n",
       "      <td>-0.229599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030692</td>\n",
       "      <td>-1.132218</td>\n",
       "      <td>-0.607190</td>\n",
       "      <td>0.709499</td>\n",
       "      <td>-0.482638</td>\n",
       "      <td>0.548393</td>\n",
       "      <td>0.343003</td>\n",
       "      <td>-0.226323</td>\n",
       "      <td>-0.337277</td>\n",
       "      <td>1.641679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284797</td>\n",
       "      <td>-0.241923</td>\n",
       "      <td>-0.284708</td>\n",
       "      <td>-0.612982</td>\n",
       "      <td>-0.066655</td>\n",
       "      <td>-0.732987</td>\n",
       "      <td>0.237948</td>\n",
       "      <td>-0.293959</td>\n",
       "      <td>-0.245496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081265</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>-0.463406</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>-1.343668</td>\n",
       "      <td>0.929369</td>\n",
       "      <td>-0.206210</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>-0.331280</td>\n",
       "      <td>1.641847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284800</td>\n",
       "      <td>2.039560</td>\n",
       "      <td>0.267772</td>\n",
       "      <td>0.523316</td>\n",
       "      <td>0.559047</td>\n",
       "      <td>-0.834660</td>\n",
       "      <td>0.626211</td>\n",
       "      <td>-0.541494</td>\n",
       "      <td>0.225361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075071</td>\n",
       "      <td>-1.196825</td>\n",
       "      <td>0.234580</td>\n",
       "      <td>-0.008713</td>\n",
       "      <td>-0.726571</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>-0.118228</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>-0.342515</td>\n",
       "      <td>1.641889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T284802</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>1.641931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class    TXKEY         V1        V10       V11        V12       V13  \\\n",
       "0         1.0   T43428 -16.526507 -14.110184  5.299236 -10.834006  1.671120   \n",
       "1         0.0   T49906   0.339812  -0.565012 -0.087670   0.979427  0.076883   \n",
       "2         0.0   T29474   1.399590   0.756801  0.543827   0.112453  1.075384   \n",
       "3         0.0  T276481  -0.432071  -1.376648 -1.328335   0.223621  1.132627   \n",
       "4         0.0  T278846   2.014160   0.259452  0.942162   0.850038 -0.616166   \n",
       "5         0.0  T101565  -0.641330  -2.084080  0.480381   0.473738 -2.192276   \n",
       "6         0.0  T260880   2.023952   0.062831 -0.720047   0.366835 -0.110857   \n",
       "7         0.0  T214337  -0.688944  -1.303435  0.282728  -0.402525 -0.548687   \n",
       "8         0.0  T201575   2.119362   0.295305 -0.936569  -0.452478 -1.340798   \n",
       "9         0.0   T81055  -5.584256  -0.942358 -2.439501  -0.552312 -0.295588   \n",
       "10        0.0  T134976  -1.593002  -0.819436  0.362193   0.436745 -1.148969   \n",
       "11        0.0  T237701   1.911979  -0.666750  0.255346   0.286835 -0.021013   \n",
       "12        0.0  T256836   1.856004   0.953865 -2.006995  -0.609613 -0.204192   \n",
       "13        0.0   T97650  -0.745324  -0.366034  0.029744   0.405037 -0.127257   \n",
       "14        0.0  T158290  -0.198807  -0.625276 -0.448324  -3.341578  0.365717   \n",
       "15        0.0  T246697  -3.608205   0.769870  0.132041   0.610286  1.033143   \n",
       "16        0.0   T68279   0.676855  -0.323058  2.967921  -0.155026 -0.717766   \n",
       "17        0.0  T267585  -2.537172   1.045582 -1.818924  -0.442261  0.609999   \n",
       "18        0.0   T26525   1.453447   1.404100 -0.758519  -0.795068  0.834501   \n",
       "19        0.0   T74422  -3.419423   1.921982  1.954445   0.388840  0.301474   \n",
       "20        0.0  T206357  -0.648081  -1.247178 -0.799046   0.665321  0.386255   \n",
       "21        0.0  T257395  -0.859208   0.733837 -1.303173   0.103792  0.612907   \n",
       "22        0.0  T283656  -3.151020   1.096035 -1.406244   0.471208 -0.226161   \n",
       "23        0.0  T231156   2.019865   0.383761  0.004929   0.167600 -0.296638   \n",
       "24        0.0   T38442  -2.151941  -2.681203 -0.595416   0.892896 -0.722106   \n",
       "25        0.0  T225485   1.786896  -0.241772 -2.203908   0.763546  1.219256   \n",
       "26        0.0   T92410   0.908419   0.031077  1.249465   0.735582 -0.857612   \n",
       "27        0.0   T10828  -1.544409  -0.722311  0.789475  -3.035002  0.568386   \n",
       "28        0.0   T61461   1.104574  -0.242497  1.112838   0.731945 -0.971919   \n",
       "29        0.0  T134354  -0.593356  -0.540724 -1.220295   0.292569 -0.376230   \n",
       "...       ...      ...        ...        ...       ...        ...       ...   \n",
       "284777    NaN  T284703   1.019594  -0.403165 -0.090503   1.230074  0.367173   \n",
       "284778    NaN  T284704  -1.269721  -1.409373 -1.749021  -0.335999  0.015538   \n",
       "284779    NaN  T284706   1.690720   1.296770 -2.004073  -0.196385  0.808469   \n",
       "284780    NaN  T284721  -2.516013   2.213231  0.492104   0.351730  1.156920   \n",
       "284781    NaN  T284725  -0.364673  -0.641531 -1.265308  -1.264948 -0.846889   \n",
       "284782    NaN  T284726   1.615707   0.394148  0.319164  -0.657936 -2.910623   \n",
       "284783    NaN  T284727  -3.240505  -0.765409 -0.341543   0.656896  0.744721   \n",
       "284784    NaN  T284732   1.076175   1.269149 -0.702987  -0.030576  1.739927   \n",
       "284785    NaN  T284735  -1.661169  -0.514510 -1.035375  -0.968981 -1.664493   \n",
       "284786    NaN  T284738  -1.117799   2.911750 -0.888295  -0.319556  1.227808   \n",
       "284787    NaN  T284740  -0.846934  -0.321648 -0.555733  -0.565739 -0.232108   \n",
       "284788    NaN  T284742  -1.248847  -2.518802 -0.743766   1.157013  0.442445   \n",
       "284789    NaN  T284748   1.634178  -0.990124 -0.321001   1.131826  1.612595   \n",
       "284790    NaN  T284753   1.465737   0.218300 -0.926921   0.218557  0.101360   \n",
       "284791    NaN  T284755  -0.954967  -1.269369 -0.960160   0.459340  0.586295   \n",
       "284792    NaN  T284760  -0.657393   0.541037 -0.131550   0.061860 -0.374501   \n",
       "284793    NaN  T284766  -0.564412  -0.452610 -0.838950   0.118004  0.355978   \n",
       "284794    NaN  T284768  -0.546378  -0.077753  0.534689   0.748099 -0.338301   \n",
       "284795    NaN  T284771   1.894910  -0.155285 -1.490405  -0.316953 -0.827955   \n",
       "284796    NaN  T284772  -6.713826   2.769699 -1.476424  -0.076365 -0.755724   \n",
       "284797    NaN  T284775   1.955547  -0.150553 -0.222844   0.496839 -0.050358   \n",
       "284798    NaN  T284778  -0.764523  -1.245088  0.874312   0.162691 -1.011819   \n",
       "284799    NaN  T284784  -0.669662  -1.453432  0.187488  -0.390794 -0.289171   \n",
       "284800    NaN  T284785   0.032887  -0.386953 -0.199626   0.032017 -0.374731   \n",
       "284801    NaN  T284788   2.007418  -0.028284 -0.635200   0.869261  0.996596   \n",
       "284802    NaN  T284789  -0.446951   0.076605 -1.291228  -0.690868 -1.481724   \n",
       "284803    NaN  T284792  -0.724123  -0.348134 -1.381624   0.617933  1.428297   \n",
       "284804    NaN  T284797  -0.241923  -0.284708 -0.612982  -0.066655 -0.732987   \n",
       "284805    NaN  T284800   2.039560   0.267772  0.523316   0.559047 -0.834660   \n",
       "284806    NaN  T284802 -11.881118   4.356170 -1.593105   2.711941 -0.689256   \n",
       "\n",
       "             V14       V15       V16    ...          V28         V3        V4  \\\n",
       "0      -9.373859  0.360806 -9.899247    ...    -1.042804 -18.649853  9.505594   \n",
       "1      -0.217884 -0.136830 -2.142892    ...     0.102038  -0.134070 -1.385729   \n",
       "2      -0.245772  0.180483  1.769860    ...     0.004634   0.168619 -1.029950   \n",
       "3      -0.550875  0.616568  0.497974    ...     0.001934  -1.669361 -0.349504   \n",
       "4       0.592634 -0.603845  0.091077    ...    -0.070571  -1.015839  0.327269   \n",
       "5       0.773942  0.294484  0.406074    ...     0.180357   1.489998 -1.688131   \n",
       "6       0.319094  0.108359 -0.153633    ...    -0.058224  -1.086918  0.423019   \n",
       "7      -0.504283 -0.685339  0.714828    ...     0.030084  -0.564281 -1.457526   \n",
       "8       1.077459 -0.099584 -0.815072    ...    -0.094713  -2.373337  0.541949   \n",
       "9      -0.250246 -1.197732  1.549553    ...    -1.898323  -0.448452 -0.121442   \n",
       "10      0.573126 -1.215218 -0.130036    ...    -0.039483   1.274002  0.244127   \n",
       "11     -1.277795  1.402421  0.712419    ...    -0.003322  -1.878744 -0.478891   \n",
       "12      0.036315  0.317903 -1.063353    ...    -0.006176  -1.094526  0.536984   \n",
       "13      1.134589  0.632135  0.237010    ...    -0.118392  -0.240708  0.592741   \n",
       "14      2.134383  0.308015 -0.519039    ...     0.289282  -0.113648 -0.246482   \n",
       "15     -1.937054  0.323444  0.261689    ...    -0.059786   0.327140  0.149964   \n",
       "16     -3.709275  0.731050  0.510125    ...    -0.383642  -1.508147  1.443815   \n",
       "17      0.493009  1.247058  0.872001    ...    -0.081702   1.204914  4.456819   \n",
       "18     -0.169291  0.368825 -0.433712    ...     0.025708  -0.134962 -1.418547   \n",
       "19     -0.427868 -0.029227 -0.075064    ...    -0.085630   1.607086  2.229979   \n",
       "20      0.251692  0.115987 -0.028040    ...    -0.071526   0.112924 -1.535076   \n",
       "21      0.245690 -0.156256 -0.587316    ...     0.510106  -1.392449 -1.416790   \n",
       "22      1.460352 -0.191831 -0.319540    ...     0.506837  -3.027658 -1.319770   \n",
       "23      1.017375  0.605096 -0.481818    ...    -0.066625  -3.296257  0.123738   \n",
       "24     -0.478067  0.007663 -1.578135    ...     0.152309   1.904957 -2.287254   \n",
       "25     -1.182939 -0.510078  0.511919    ...    -0.022000   0.169414  0.716106   \n",
       "26      0.158029  0.219705  0.178133    ...     0.036881   1.213928  1.350973   \n",
       "27      1.287709 -0.461989  1.132222    ...     0.191005   0.671990 -0.625734   \n",
       "28     -0.034381 -0.048560  0.111454    ...     0.003023   1.127897  0.019039   \n",
       "29     -0.608940 -1.441187 -1.001776    ...     0.162494   0.656265  0.642976   \n",
       "...          ...       ...       ...    ...          ...        ...       ...   \n",
       "284777  0.173777 -0.563206  0.246397    ...     0.039078  -1.431268  0.539727   \n",
       "284778 -1.098655  0.473234  1.015379    ...    -0.135902   0.131330 -1.065236   \n",
       "284779 -0.418867 -0.530816  1.419129    ...    -0.009875  -0.299329  3.698813   \n",
       "284780 -2.276737  0.803360 -0.700136    ...    -0.222766  -0.683786 -0.621718   \n",
       "284781 -0.272673  2.381906 -0.474342    ...     0.089564  -0.728575  0.942156   \n",
       "284782  0.819779  0.511679  0.777601    ...    -0.012795  -0.562272  1.260583   \n",
       "284783  0.067701  0.621832  1.051746    ...    -0.501609   1.749777  0.332355   \n",
       "284784 -0.262265 -0.561099 -0.902514    ...     0.056029  -2.051439 -0.953189   \n",
       "284785 -0.370165 -0.280621  0.371750    ...    -0.448621   0.294268 -1.549156   \n",
       "284786 -0.829885  0.875202 -0.094147    ...     0.273686   1.822761  4.243919   \n",
       "284787 -0.591077 -0.183204  1.705102    ...     0.166451   2.160620 -1.935812   \n",
       "284788 -0.078341 -0.461857  0.477430    ...     0.082714  -1.144824 -0.263061   \n",
       "284789 -1.754129 -0.236948 -0.011848    ...     0.024884  -1.975967  0.495364   \n",
       "284790  0.916400 -0.231472 -0.825682    ...    -0.014737  -2.851391  1.425282   \n",
       "284791  0.101810  0.578975  0.046778    ...     0.014827   1.780434 -0.361532   \n",
       "284792  0.143281  0.087590 -0.217749    ...     0.281084  -1.498162 -1.889374   \n",
       "284793  0.100859  0.256386 -1.846704    ...    -0.155795   0.001107 -1.775612   \n",
       "284794  1.018502 -1.058923 -0.914161    ...     0.173585  -0.313252  0.926044   \n",
       "284795  0.743761  0.642005 -0.380035    ...    -0.040441  -2.184267  0.159979   \n",
       "284796  0.758186  1.018209  0.099797    ...     0.474584  -3.534768 -0.368259   \n",
       "284797  0.001067  0.894690  0.001418    ...    -0.042323  -1.706511 -0.611145   \n",
       "284798 -0.317789 -0.887823  0.482847    ...    -0.065285  -0.907599 -0.418847   \n",
       "284799 -0.510320  0.955637  0.553781    ...    -0.187719  -1.543167 -1.560729   \n",
       "284800  0.354051  0.041228 -0.154750    ...     0.090245  -1.185844 -1.729828   \n",
       "284801 -0.280317  0.436079  0.397439    ...    -0.041367  -0.208113  0.335261   \n",
       "284802  0.753473 -0.191141 -1.129904    ...     0.229921  -0.168583  0.981577   \n",
       "284803  0.494490  0.426827 -0.229599    ...    -0.030692  -1.132218 -0.607190   \n",
       "284804  0.237948 -0.293959 -0.245496    ...     0.081265   0.399806 -0.463406   \n",
       "284805  0.626211 -0.541494  0.225361    ...    -0.075071  -1.196825  0.234580   \n",
       "284806  4.626942 -0.924459  1.107641    ...     0.823731  -9.834783 -2.066656   \n",
       "\n",
       "               V5        V6         V7        V8        V9  normAmount  \\\n",
       "0      -13.793819 -2.832404 -16.701694  7.517344 -8.507059    1.102834   \n",
       "1       -1.451413  1.015887  -0.524379  0.224060  0.899746    1.726255   \n",
       "2       -0.539806  0.040444  -0.712567  0.002299 -0.971747   -0.229289   \n",
       "3        0.785785 -0.630647   0.276990  0.586025 -0.484715   -0.347232   \n",
       "4       -0.182179 -0.956571   0.043241 -0.160746  0.363241   -0.349671   \n",
       "5       -1.151043  0.259996  -1.391069 -2.334075  1.168644    0.046579   \n",
       "6       -0.142901 -1.127752   0.178493 -0.303234  0.564509   -0.285302   \n",
       "7        2.258333 -0.323270   1.678984 -0.104128 -1.285351   -0.317447   \n",
       "8        0.608419 -1.775564   0.955775 -0.599383  0.010420   -0.313249   \n",
       "9       -0.707412 -0.114376  -1.554628  1.402126 -0.031693    0.052536   \n",
       "10       0.335045  0.272886   0.389542  0.676944 -0.579539   -0.179313   \n",
       "11       1.775020  3.807866  -1.349298  1.116637  1.329865   -0.266831   \n",
       "12      -0.460547  0.257930  -0.548791 -0.006732 -0.136465    0.270472   \n",
       "13       0.036572  0.642731  -0.098414  1.009457 -0.931697   -0.185310   \n",
       "14       0.751390 -0.359111   0.493849 -0.948922  1.573062   -0.349231   \n",
       "15       3.666915 -2.701360  -1.340508 -0.522986  1.115929   -0.319086   \n",
       "16       1.316790 -1.160342   1.149049 -0.419393 -0.090565   -0.349671   \n",
       "17      -0.829264  1.473885  -1.182380  1.467687 -1.750166   -0.247400   \n",
       "18      -1.057755 -0.948851  -0.461141 -0.350840 -2.149149   -0.049375   \n",
       "19       2.644089 -0.793538   1.088242 -1.008410 -0.933315   -0.262473   \n",
       "20      -0.191904 -1.208250   0.453343  0.180405  0.389545   -0.169917   \n",
       "21       1.290569 -1.433808   1.730253 -0.468233  0.287973   -0.349231   \n",
       "22      -0.570469 -2.085578   0.223991  1.296731  0.480108   -0.323963   \n",
       "23       3.078086  3.037019   0.197002  0.576984 -0.306510   -0.257275   \n",
       "24      -0.330618 -0.971106  -0.067533  0.251995  2.391839    0.773991   \n",
       "25      -0.991835  0.798244  -1.181350  0.232048  2.037239    0.082562   \n",
       "26      -0.952296  0.428768  -0.683379  0.366450  0.554730   -0.005396   \n",
       "27       1.953606  0.231276  -0.017919  0.125894  1.198210   -0.265311   \n",
       "28      -1.083712  0.308094  -0.917052  0.377067  0.969331   -0.265471   \n",
       "29       1.974441  4.632349  -0.366834  1.219162  0.412184    0.022391   \n",
       "...           ...       ...        ...       ...       ...         ...   \n",
       "284777  -0.499995  0.301251   0.326079 -0.062475  1.121288    1.733372   \n",
       "284778   0.107397 -0.307148   0.001854  0.678313  0.459493   -0.350151   \n",
       "284779   0.190589  1.137963  -0.405899  0.186784 -0.307412    0.162204   \n",
       "284780   0.596987 -1.384147   1.579089 -1.314013  1.618929   -0.323444   \n",
       "284781   0.690695 -0.142101   0.279193  0.304228 -0.563470   -0.311010   \n",
       "284782  -0.684711  0.234819  -0.643286  0.329931  1.064298    0.286464   \n",
       "284783   1.535180 -0.574599  -2.131128  1.034499  0.110722   -0.145329   \n",
       "284784  -1.544838 -1.124645   0.385570 -0.698014 -1.829401    2.303899   \n",
       "284785  -2.301359  2.365956  -0.248881 -0.857361  0.137784    1.170241   \n",
       "284786   0.043986  0.761828   0.297293 -0.111319 -0.769844   -0.301854   \n",
       "284787  -1.864416 -0.939825  -0.972629  0.600049 -0.266026   -0.305292   \n",
       "284788   0.070912 -0.323414  -1.454139 -5.069379 -0.827733   -0.313289   \n",
       "284789   0.263635 -0.713049   0.459925 -0.336879  0.743676    0.527469   \n",
       "284790   0.893893 -0.958325   1.508074 -0.625691 -0.369824    0.996285   \n",
       "284791  -0.407570 -0.406413   0.210387  0.429851 -0.173493   -0.313289   \n",
       "284792   2.819520  3.333925   0.287569  0.958604  0.408711   -0.346113   \n",
       "284793   0.116635  1.116266  -0.211710  0.823119 -1.024449    0.029108   \n",
       "284794   0.522388 -0.565669   1.066075  0.269799 -1.099446   -0.207259   \n",
       "284795   0.587740 -0.557966   0.510524 -0.281590  0.785446    0.146491   \n",
       "284796  -1.721030 -1.322808  -0.190876  0.891149  2.068476   -0.274907   \n",
       "284797   1.710907  3.914215  -1.248690  1.054133  1.314064   -0.301294   \n",
       "284798   0.901528 -0.760802   0.758545  0.414698 -0.730854   -0.033382   \n",
       "284799   2.833960  3.240843   0.181576  1.282746 -0.893890   -0.193306   \n",
       "284800   2.932315  3.401529   0.337434  0.925377 -0.165663   -0.346073   \n",
       "284801  -0.715798 -0.751373  -0.458972 -0.140140  0.959971   -0.337277   \n",
       "284802   0.578957 -0.605641   1.253430 -1.042610 -0.417116   -0.111345   \n",
       "284803   0.709499 -0.482638   0.548393  0.343003 -0.226323   -0.337277   \n",
       "284804   0.244531 -1.343668   0.929369 -0.206210  0.106234   -0.331280   \n",
       "284805  -0.008713 -0.726571   0.017050 -0.118228  0.435402   -0.342515   \n",
       "284806  -5.364473 -2.606837  -4.918215  7.305334  1.914428   -0.350151   \n",
       "\n",
       "        normTime  \n",
       "0      -1.122574  \n",
       "1      -1.064538  \n",
       "2      -1.249364  \n",
       "3       1.522680  \n",
       "4       1.551109  \n",
       "5      -0.567213  \n",
       "6       1.367694  \n",
       "7       0.943756  \n",
       "8       0.824000  \n",
       "9      -0.759030  \n",
       "10     -0.289733  \n",
       "11      1.148565  \n",
       "12      1.328147  \n",
       "13     -0.600127  \n",
       "14      0.343289  \n",
       "15      1.231386  \n",
       "16     -0.882345  \n",
       "17      1.432426  \n",
       "18     -1.278129  \n",
       "19     -0.826289  \n",
       "20      0.871022  \n",
       "21      1.333580  \n",
       "22      1.620452  \n",
       "23      1.091246  \n",
       "24     -1.167027  \n",
       "25      1.041380  \n",
       "26     -0.650561  \n",
       "27     -1.607243  \n",
       "28     -0.946888  \n",
       "29     -0.295777  \n",
       "...          ...  \n",
       "284777  1.640099  \n",
       "284778  1.640120  \n",
       "284779  1.640120  \n",
       "284780  1.640331  \n",
       "284781  1.640373  \n",
       "284782  1.640436  \n",
       "284783  1.640457  \n",
       "284784  1.640563  \n",
       "284785  1.640689  \n",
       "284786  1.640773  \n",
       "284787  1.640815  \n",
       "284788  1.640836  \n",
       "284789  1.640921  \n",
       "284790  1.641026  \n",
       "284791  1.641047  \n",
       "284792  1.641152  \n",
       "284793  1.641300  \n",
       "284794  1.641342  \n",
       "284795  1.641363  \n",
       "284796  1.641384  \n",
       "284797  1.641426  \n",
       "284798  1.641468  \n",
       "284799  1.641552  \n",
       "284800  1.641552  \n",
       "284801  1.641594  \n",
       "284802  1.641594  \n",
       "284803  1.641679  \n",
       "284804  1.641847  \n",
       "284805  1.641889  \n",
       "284806  1.641931  \n",
       "\n",
       "[284807 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把train test合併一起做feature engineering\n",
    "df = train.append(test, sort=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df['normAmount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['normTime'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1,1))\n",
    "df = df.drop(['Amount','Time'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('TXKEY', axis=1)\n",
    "train = df[df['Class'].notnull()]\n",
    "test = df[df['Class'].isnull()]\n",
    "x_train = train.drop('Class', axis=1)\n",
    "y_train = train['Class']\n",
    "x_test = test.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 199364 entries, 0 to 199363\n",
      "Data columns (total 30 columns):\n",
      "V1            199364 non-null float64\n",
      "V10           199364 non-null float64\n",
      "V11           199364 non-null float64\n",
      "V12           199364 non-null float64\n",
      "V13           199364 non-null float64\n",
      "V14           199364 non-null float64\n",
      "V15           199364 non-null float64\n",
      "V16           199364 non-null float64\n",
      "V17           199364 non-null float64\n",
      "V18           199364 non-null float64\n",
      "V19           199364 non-null float64\n",
      "V2            199364 non-null float64\n",
      "V20           199364 non-null float64\n",
      "V21           199364 non-null float64\n",
      "V22           199364 non-null float64\n",
      "V23           199364 non-null float64\n",
      "V24           199364 non-null float64\n",
      "V25           199364 non-null float64\n",
      "V26           199364 non-null float64\n",
      "V27           199364 non-null float64\n",
      "V28           199364 non-null float64\n",
      "V3            199364 non-null float64\n",
      "V4            199364 non-null float64\n",
      "V5            199364 non-null float64\n",
      "V6            199364 non-null float64\n",
      "V7            199364 non-null float64\n",
      "V8            199364 non-null float64\n",
      "V9            199364 non-null float64\n",
      "normAmount    199364 non-null float64\n",
      "normTime      199364 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 47.2 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# print('Load data...')\n",
    "# df_train = pd.read_csv('data/train.csv')\n",
    "# df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\n",
    "    \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\",\n",
    "]\n",
    "\n",
    "# print(df_test.head(10))\n",
    "\n",
    "# y_train = df_train['target']  # training label\n",
    "# y_test = df_test['target']  # testing label\n",
    "# X_train = df_train[NUMERIC_COLS]  # training dataset\n",
    "# X_test = df_test[NUMERIC_COLS]  # testing dataset\n",
    "\n",
    "# # create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "# lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DavidHuang/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:102: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model...\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 64,\n",
    "    'num_trees': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# number of leaves,will be used in feature transformation\n",
    "num_leaf = 64\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100)\n",
    "#                 valid_sets=lgb_train)\n",
    "\n",
    "print('Save model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "(199364, 100)\n",
      "[[ 4 50 53  6 54 43  6  6 20 21 48 54 54 45 43  4 44 31 26 51 49 39 57 52\n",
      "   2 27 34 12 58 13  0 32 24 23  0 59 62 28 30  7 22 21 16 11 21 55 55 53\n",
      "  49 54 32 31 32 27 35 32 33 50 36 37 61 43 55 58 30 55 43 45 42 42 52 50\n",
      "  61 31 29 38 24 46 58 42 35 29 47 28 31 50 54 50 52 34 48 46 24 43 26 39\n",
      "  39 36 46 47]\n",
      " [57 47 61 43 60 47 62 56 62 56 52 43 57 48 51 58 36 38 33 33 39 60 49 61\n",
      "  48 43 39 40 34 60 63 62 45 46 53 51 42 17 51 16 53 50 50 53 50 25 27 63\n",
      "  42 24 58 57 57 49 60  1  1 46  1  1 51 49 12 49 52 13 13 20 12 12 25  1\n",
      "   1 20  1 42 45 20 19 21 50 49 59 52 57 19 21 20 17 58 19 18 16 19 16 28\n",
      "  30 56 48 48]\n",
      " [57 47 61 43 60 47 62 56 62 56 61 43 59 56 53 58 36 38 33 33 39 60 49 61\n",
      "  48 43 39 40 34 60 46 62 45 46 53 51 42 60 51 63 53 50 50 53 50 25 27 63\n",
      "  54 24 58 57 57 49 60  1  1 59  1  1 51 49 12 49 52 30  1  1  1  1 25 35\n",
      "  37 20 45 42 45 20 19 21 50 49 59 52 44 19 21 20 17 58 37 18 16 19 16 28\n",
      "  30 56 48 48]\n",
      " [43 47 14 43 16 47 62 56 62 56 44 43 59 63 57 58 36 38 33 33 39 40 49 46\n",
      "  48 43 39 40 34 60  3 63 45 46 54 51 42 39 51 39 53 50 50 53 50 25 27 63\n",
      "  34 24 62 61 61 50 20  1  1 26  1  1 51 49 12 49 52 30  1  1  1  1 25 40\n",
      "   1 20 49 48 51 21 20 22 50 49 59 52 44  1  1  1  1 58 22 18 16 19 16 28\n",
      "  30 56  6  6]\n",
      " [57 47 61 43 60 47 62 56 62 56 61 43 59 56 53 58 36 38 33 33 39 60 49 61\n",
      "  48 43 39 40 34 60 46 62 56 56 53 51 42 60 51 63 53 50 50 53 50 25 27 63\n",
      "  54 24 58 57 57 49 60  1  1 59  1  1 51 49 12 49 52 30  1  1  1  1 25 35\n",
      "  37 20 45 42 45 20 19 21 50 49 59 52 44 19 21 20 17 13 37 18 16 19 16 28\n",
      "  30 56 48 48]\n",
      " [57 47 61 14 60 51 62 56 62 56 61 43 34 56 53 58 36 38 33 33  0 60  0  0\n",
      "   0 43 39 40 34 60 46 16 56 56 44 52 14 60 52 63 53 50 50 53 50 25 27 63\n",
      "  62 24 58 57 57 52 60  1  1  4  1  1 51  0 12 49 52 30  1  1  1  1 23  1\n",
      "   1 20  1 42 45 20 19 21 50 49  3 52 44 19 21 20 17 23  8 18 16 19 16 28\n",
      "  30 56 17 17]\n",
      " [57 47 61 43 60 47 62 56 62 56 61 43 59 56 53 58 36 38 33 33 39 60 49 61\n",
      "  48 43 39 40 34 60 46 62 45 46 53 51 42 60 51 63 53 50 50 53 50 25 27 63\n",
      "  54 24 58 57 57 49 60  1  1 59  1  1 51 49 12 49 52 30  1  1  1  1 25 35\n",
      "  37 20 45 42 45 20 19 21 50 49 59 52 44 19 21 20 17 58 37 18 16 19 16 28\n",
      "  30 56 48 48]\n",
      " [43 47 14 43 16 47 62 56 62 56 44 43 59 63 57 60 60 57 61 62 39 56 49 46\n",
      "  48 43 39 40 34 49  3 63 45 46 54 56 48 39 14 39 47 39 41 18 41 25 27 63\n",
      "  34 24 62 61 61 50 20  1  1 26  1  1 44 49 47 43 44 30  1  1  1  1 30 40\n",
      "  45 17 49 48 51 21 20 22 50 49 59 52 44 42 44 43 43 58 22  5 33  5 35 34\n",
      "  37 31  6  6]\n",
      " [57 47 61 43 60 47 62 56 62 56 61 43 59 56 53 58 36 38 33 33 39 60 49 61\n",
      "  48 43 39 40 34 60 46 62 56 56 53 51 42 60 51 63 53 50 50 53 50 25 27 63\n",
      "  54 24 58 57 57 49 60  1  1 59  1  1 51 50 12 49 52 30  1  1  1  1 25 35\n",
      "  37 20 45 42 45 20 19 21 50 49 59 52 44 19 21 20 17 63 37 18 16 19 16 28\n",
      "  30 56 48 48]\n",
      " [57 47 61 60 60 23 38 19 62 17 61 43 59 56 53 58 36 38 33  1 39 60 49 61\n",
      "  48 43 39 40 34 60 46 38 45 46 53 51 42 60 51 63 54 51 50 57 51 11  7  7\n",
      "  54  6 58 57 57 33 60  1  1 27  1  1 51 49 12 49 52  1  1  1  1  1 37 40\n",
      "   1 21 49 17 16 20 19 21  1  1  1  1  1 19 21 20 17 63 37 18 16 19 16 12\n",
      "  22 56  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "# predict and get data on leaves, training data\n",
    "y_pred = gbm.predict(x_train, pred_leaf=True)\n",
    "\n",
    "print(np.array(y_pred).shape)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_training_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf],\n",
    "                                       dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 6400)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_training_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed training data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5355be0f150f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Writing transformed testing data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtransformed_testing_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_leaf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "print('Writing transformed training data')\n",
    "transformed_training_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf],\n",
    "                                       dtype=np.int64)  # N * num_tress * num_leafs\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_training_matrix[i][temp] += 1\n",
    "\n",
    "\n",
    "y_pred = gbm.predict(X_test, pred_leaf=True)\n",
    "print('Writing transformed testing data')\n",
    "transformed_testing_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf], dtype=np.int64)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_testing_matrix[i][temp] += 1\n",
    "\n",
    "\n",
    "lm = LogisticRegression(penalty='l2',C=0.05) # logestic model construction\n",
    "lm.fit(transformed_training_matrix,y_train)  # fitting the data\n",
    "y_pred_test = lm.predict_proba(transformed_testing_matrix)   # Give the probabilty on each label\n",
    "\n",
    "print(y_pred_test)\n",
    "\n",
    "NE = (-1) / len(y_pred_test) * sum(((1+y_test)/2 * np.log(y_pred_test[:,1]) +  (1-y_test)/2 * np.log(1 - y_pred_test[:,1])))\n",
    "print(\"Normalized Cross Entropy \" + str(NE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    f1 score\n",
    "\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tp_3d = K.concatenate(\n",
    "        [\n",
    "            K.cast(y_true, 'bool'),\n",
    "            K.cast(K.round(y_pred), 'bool'),\n",
    "            K.cast(K.ones_like(y_pred), 'bool')\n",
    "        ], axis=1\n",
    "    )\n",
    "\n",
    "    fp_3d = K.concatenate(\n",
    "        [\n",
    "            K.cast(K.abs(y_true - K.ones_like(y_true)), 'bool'),\n",
    "            K.cast(K.round(y_pred), 'bool'),\n",
    "            K.cast(K.ones_like(y_pred), 'bool')\n",
    "        ], axis=1\n",
    "    )\n",
    "\n",
    "    fn_3d = K.concatenate(\n",
    "        [\n",
    "            K.cast(y_true, 'bool'),\n",
    "            K.cast(K.abs(K.round(y_pred) - K.ones_like(y_pred)), 'bool'),\n",
    "            K.cast(K.ones_like(y_pred), 'bool')\n",
    "        ], axis=1\n",
    "    )\n",
    "\n",
    "    tp = K.sum(K.cast(K.all(tp_3d, axis=1), 'int32'))\n",
    "    fp = K.sum(K.cast(K.all(fp_3d, axis=1), 'int32'))\n",
    "    fn = K.sum(K.cast(K.all(fn_3d, axis=1), 'int32'))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, input_dim=x_train.shape[1], kernel_initializer='lecun_normal', activation='relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "# # model.add(Dense(64, activation='relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "# # model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dense(1, kernel_initializer='lecun_normal', activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           epochs=10,\n",
    "#           batch_size=64)\n",
    "# score = model.evaluate(x_train, y_train, batch_size=128)\n",
    "\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=x_train.shape[1], kernel_initializer='lecun_normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='lecun_normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.get_layer of <keras.models.Sequential object at 0x11068ea20>>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train, epochs=100, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 82.32% (3.73%)\n",
      "CPU times: user 1h 3min 56s, sys: 12min 43s, total: 1h 16min 40s\n",
      "Wall time: 45min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=64, verbose=0)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv=5, scoring='f1')\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-6c046743cf7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/DavidHuang/anaconda/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[1;32m    254\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# check if binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "estimator.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ec0d48a82b48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/DavidHuang/anaconda/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "y_train_predict = estimator.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015040776"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-38bdf359dfec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/DavidHuang/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \"\"\"\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DavidHuang/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_train, y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xxx= t.Tensor(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xxx=t.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
